{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import model_selection, svm\n\nimport seaborn as sns; sns.set_theme()\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-24T02:33:44.799000Z","iopub.execute_input":"2021-10-24T02:33:44.799351Z","iopub.status.idle":"2021-10-24T02:33:44.813698Z","shell.execute_reply.started":"2021-10-24T02:33:44.799314Z","shell.execute_reply":"2021-10-24T02:33:44.812498Z"},"trusted":true},"execution_count":650,"outputs":[]},{"cell_type":"markdown","source":"# importando nosso dataframe","metadata":{}},{"cell_type":"code","source":"#carrega a base de treino\ndf=pd.read_csv(r\"../input/churn-data/BankChurners.csv\",encoding='latin-1')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:45.148620Z","iopub.execute_input":"2021-10-24T02:33:45.149684Z","iopub.status.idle":"2021-10-24T02:33:45.201621Z","shell.execute_reply.started":"2021-10-24T02:33:45.149621Z","shell.execute_reply":"2021-10-24T02:33:45.200463Z"},"trusted":true},"execution_count":651,"outputs":[]},{"cell_type":"markdown","source":"# Removendo colunas desnecessarias","metadata":{}},{"cell_type":"markdown","source":"as duas ultimas colunas causam sobreajuste dos dados.","metadata":{}},{"cell_type":"code","source":"x = df.drop(['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n             'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'\n             ,'Attrition_Flag','CLIENTNUM'],axis='columns')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:45.210721Z","iopub.execute_input":"2021-10-24T02:33:45.211079Z","iopub.status.idle":"2021-10-24T02:33:45.218788Z","shell.execute_reply.started":"2021-10-24T02:33:45.211046Z","shell.execute_reply":"2021-10-24T02:33:45.217828Z"},"trusted":true},"execution_count":652,"outputs":[]},{"cell_type":"markdown","source":"# Como os dados se comportam ?","metadata":{}},{"cell_type":"code","source":"df.sample(n=10)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:45.220667Z","iopub.execute_input":"2021-10-24T02:33:45.220983Z","iopub.status.idle":"2021-10-24T02:33:45.267747Z","shell.execute_reply.started":"2021-10-24T02:33:45.220932Z","shell.execute_reply":"2021-10-24T02:33:45.264798Z"},"trusted":true},"execution_count":653,"outputs":[]},{"cell_type":"code","source":"x.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:45.269854Z","iopub.execute_input":"2021-10-24T02:33:45.270536Z","iopub.status.idle":"2021-10-24T02:33:45.298966Z","shell.execute_reply.started":"2021-10-24T02:33:45.270483Z","shell.execute_reply":"2021-10-24T02:33:45.298173Z"},"trusted":true},"execution_count":654,"outputs":[]},{"cell_type":"markdown","source":"## Não apresentarei boxplots que não possuem otliers para não sobrecarregar a quantidade de boxplot no arquivo python.","metadata":{}},{"cell_type":"code","source":"boxplot = df.boxplot(column=['Months_on_book'])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:45.300920Z","iopub.execute_input":"2021-10-24T02:33:45.301635Z","iopub.status.idle":"2021-10-24T02:33:45.530444Z","shell.execute_reply.started":"2021-10-24T02:33:45.301569Z","shell.execute_reply":"2021-10-24T02:33:45.529324Z"},"trusted":true},"execution_count":655,"outputs":[]},{"cell_type":"code","source":"boxplot = df.boxplot(column=['Months_Inactive_12_mon'])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:45.533552Z","iopub.execute_input":"2021-10-24T02:33:45.534648Z","iopub.status.idle":"2021-10-24T02:33:45.793097Z","shell.execute_reply.started":"2021-10-24T02:33:45.534329Z","shell.execute_reply":"2021-10-24T02:33:45.791958Z"},"trusted":true},"execution_count":656,"outputs":[]},{"cell_type":"code","source":"sns.histplot((df['Total_Revolving_Bal']), kde=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:45.794688Z","iopub.execute_input":"2021-10-24T02:33:45.795052Z","iopub.status.idle":"2021-10-24T02:33:46.276816Z","shell.execute_reply.started":"2021-10-24T02:33:45.795002Z","shell.execute_reply":"2021-10-24T02:33:46.275916Z"},"trusted":true},"execution_count":657,"outputs":[]},{"cell_type":"code","source":"boxplot = df.boxplot(column=['Credit_Limit'])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:46.278465Z","iopub.execute_input":"2021-10-24T02:33:46.279499Z","iopub.status.idle":"2021-10-24T02:33:46.514620Z","shell.execute_reply.started":"2021-10-24T02:33:46.279446Z","shell.execute_reply":"2021-10-24T02:33:46.513474Z"},"trusted":true},"execution_count":658,"outputs":[]},{"cell_type":"code","source":"sns.histplot((df['Credit_Limit']), kde=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:46.516336Z","iopub.execute_input":"2021-10-24T02:33:46.516722Z","iopub.status.idle":"2021-10-24T02:33:47.072086Z","shell.execute_reply.started":"2021-10-24T02:33:46.516676Z","shell.execute_reply":"2021-10-24T02:33:47.070971Z"},"trusted":true},"execution_count":659,"outputs":[]},{"cell_type":"code","source":"\nsns.histplot((df['Avg_Open_To_Buy']), kde=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:47.073316Z","iopub.execute_input":"2021-10-24T02:33:47.073928Z","iopub.status.idle":"2021-10-24T02:33:47.572923Z","shell.execute_reply.started":"2021-10-24T02:33:47.073889Z","shell.execute_reply":"2021-10-24T02:33:47.570685Z"},"trusted":true},"execution_count":660,"outputs":[]},{"cell_type":"code","source":"boxplot = df.boxplot(column=['Avg_Open_To_Buy'])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:47.574614Z","iopub.execute_input":"2021-10-24T02:33:47.574887Z","iopub.status.idle":"2021-10-24T02:33:47.761104Z","shell.execute_reply.started":"2021-10-24T02:33:47.574856Z","shell.execute_reply":"2021-10-24T02:33:47.759866Z"},"trusted":true},"execution_count":661,"outputs":[]},{"cell_type":"code","source":"sns.histplot((df['Total_Amt_Chng_Q4_Q1']), kde=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:47.763034Z","iopub.execute_input":"2021-10-24T02:33:47.763679Z","iopub.status.idle":"2021-10-24T02:33:48.581900Z","shell.execute_reply.started":"2021-10-24T02:33:47.763625Z","shell.execute_reply":"2021-10-24T02:33:48.580701Z"},"trusted":true},"execution_count":662,"outputs":[]},{"cell_type":"code","source":"boxplot = df.boxplot(column=['Total_Trans_Ct'])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:48.583200Z","iopub.execute_input":"2021-10-24T02:33:48.583466Z","iopub.status.idle":"2021-10-24T02:33:48.751582Z","shell.execute_reply.started":"2021-10-24T02:33:48.583429Z","shell.execute_reply":"2021-10-24T02:33:48.750975Z"},"trusted":true},"execution_count":663,"outputs":[]},{"cell_type":"code","source":"sns.histplot((df['Total_Ct_Chng_Q4_Q1']), kde=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:48.752530Z","iopub.execute_input":"2021-10-24T02:33:48.752843Z","iopub.status.idle":"2021-10-24T02:33:49.575282Z","shell.execute_reply.started":"2021-10-24T02:33:48.752815Z","shell.execute_reply":"2021-10-24T02:33:49.574468Z"},"trusted":true},"execution_count":664,"outputs":[]},{"cell_type":"markdown","source":"# Tratando alguns outliers","metadata":{}},{"cell_type":"code","source":"#esta função encontra os limites superiores e inferiores\n# e retorna o dataframe dentro dos limites\ndef boxplott(df,text):\n    #df=df.sort_values(text)\n    Q1=df[text].quantile(q=0.25)\n    Q3=df[text].quantile(q=0.75)\n    FIQ = Q3-Q1\n\n    LF = Q1 - 1.5 * FIQ\n    LS = Q3 + 1.5 * FIQ\n    \n    #print('LS : ', LS)\n    #print('LF : ', LF)\n    df.loc[df[text] > LS , text] = LS\n    df.loc[df[text] < LF , text] = LF\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:49.578140Z","iopub.execute_input":"2021-10-24T02:33:49.578390Z","iopub.status.idle":"2021-10-24T02:33:49.585841Z","shell.execute_reply.started":"2021-10-24T02:33:49.578359Z","shell.execute_reply":"2021-10-24T02:33:49.584624Z"},"trusted":true},"execution_count":665,"outputs":[]},{"cell_type":"markdown","source":"### Vamos converter algumas colunas para seu logaritmo, isso faz com que reduza levemente os outliers da coluna especifica.\n### outra abordagem é quando em uma coluna há poucos outlier aplico a função boxplott que reduz os outliers. Em algumas situações pode se mostrar ineficiente mas aqui aumentou levemente a accuracy.","metadata":{}},{"cell_type":"code","source":"x['Total_Amt_Chng_Q4_Q1']=np.log(x['Total_Amt_Chng_Q4_Q1']+1)\nx['Avg_Open_To_Buy']=np.log(x['Avg_Open_To_Buy']+1)\nx['Total_Ct_Chng_Q4_Q1']=np.log(x['Total_Ct_Chng_Q4_Q1']+1)\nx = boxplott(x,'Months_on_book')\nx = boxplott(x,'Months_Inactive_12_mon')\nx = boxplott(x,'Contacts_Count_12_mon')\nx = boxplott(x,'Total_Trans_Ct')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:49.587617Z","iopub.execute_input":"2021-10-24T02:33:49.588259Z","iopub.status.idle":"2021-10-24T02:33:49.619388Z","shell.execute_reply.started":"2021-10-24T02:33:49.588219Z","shell.execute_reply":"2021-10-24T02:33:49.618385Z"},"trusted":true},"execution_count":666,"outputs":[]},{"cell_type":"markdown","source":"# O que utilizar? Label encoder ou OneHotEncoder?\n\nTestei ambas abordagens e cheguei a conclusão que Label Encoder foi mais promissor se tratando dos dois modelos de ML que utilizei. Talvez em uma rede neural a abordagem mudaria.","metadata":{}},{"cell_type":"markdown","source":"### Label encoder","metadata":{}},{"cell_type":"code","source":"\nlabelencoder = LabelEncoder()\nx['Gender'] = labelencoder.fit_transform(x['Gender'])\nx['Education_Level'] = labelencoder.fit_transform(x['Education_Level'])\nx['Marital_Status'] = labelencoder.fit_transform(x['Marital_Status'])\nx['Income_Category'] = labelencoder.fit_transform(x['Income_Category'])\nx['Card_Category'] = labelencoder.fit_transform(x['Card_Category'])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:49.621477Z","iopub.execute_input":"2021-10-24T02:33:49.621772Z","iopub.status.idle":"2021-10-24T02:33:49.651957Z","shell.execute_reply.started":"2021-10-24T02:33:49.621741Z","shell.execute_reply":"2021-10-24T02:33:49.651314Z"},"trusted":true},"execution_count":667,"outputs":[]},{"cell_type":"markdown","source":"### one hot encoder :","metadata":{}},{"cell_type":"code","source":"#x = pd.get_dummies(x)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:49.653210Z","iopub.execute_input":"2021-10-24T02:33:49.654071Z","iopub.status.idle":"2021-10-24T02:33:49.658548Z","shell.execute_reply.started":"2021-10-24T02:33:49.654033Z","shell.execute_reply":"2021-10-24T02:33:49.657507Z"},"trusted":true},"execution_count":668,"outputs":[]},{"cell_type":"markdown","source":"### Como ficaram os dados?","metadata":{}},{"cell_type":"code","source":"x.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:49.660012Z","iopub.execute_input":"2021-10-24T02:33:49.660987Z","iopub.status.idle":"2021-10-24T02:33:49.691324Z","shell.execute_reply.started":"2021-10-24T02:33:49.660936Z","shell.execute_reply":"2021-10-24T02:33:49.690173Z"},"trusted":true},"execution_count":669,"outputs":[]},{"cell_type":"markdown","source":"# SEPARAÇÃO TREINO E TESTE","metadata":{}},{"cell_type":"code","source":"#Separação entre treino e teste\ny=df['Attrition_Flag']\n#del df \n\nnp.random.seed(50)\nx_treino, x_teste, y_treino, y_teste = train_test_split (x, y, test_size = 0.20, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:49.692951Z","iopub.execute_input":"2021-10-24T02:33:49.693201Z","iopub.status.idle":"2021-10-24T02:33:49.706284Z","shell.execute_reply.started":"2021-10-24T02:33:49.693170Z","shell.execute_reply":"2021-10-24T02:33:49.705304Z"},"trusted":true},"execution_count":670,"outputs":[]},{"cell_type":"markdown","source":"# FASE DE TREINAMENTO E TESTE\n\n##### OPITEI POR UTILIZAR DOIS MODELOS DE ML QUE SÃO EXTREMAMENTE RAPIDOS, O PRIMIERO É XGB E O SEGUNDO RANDO FOREST\n##### TESTEI SVM MAS SE MOSTROU EXTREMAMENTE LENTO, ENTÃO OPTEI POR REMOVELO POIS NÃO HAVERIA TEMPO PARA EXECUÇÃO.\n##### DEIXEI O MODELO DESCOBRIR SEUS PARAMETROS PARA NÃO CAUSAR SOBRE AJUSTE TAMBÈM PORQUE NÃO HAVERIA TEMPO PARA TESTES COM DIVERSOS PARAMETROS.\n\n##### VALE COMENTAR QUE UTILIZEI 5 FOLDS e MATRIZ DE CONFUSÃO PARA INTERPRETAR OS RESULTADOS. AO FINAL HÁ UM BREVE COMENTARIO SOBRE OS TESTES E SEUS RESPECTIVOS RESULTADOS.","metadata":{}},{"cell_type":"markdown","source":"# TREINAMENTO XGB","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nSVM = XGBClassifier(verbosity = 0)\nSVM.fit(x_treino,y_treino)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:49.707951Z","iopub.execute_input":"2021-10-24T02:33:49.709068Z","iopub.status.idle":"2021-10-24T02:33:50.552943Z","shell.execute_reply.started":"2021-10-24T02:33:49.708955Z","shell.execute_reply":"2021-10-24T02:33:50.552171Z"},"trusted":true},"execution_count":671,"outputs":[]},{"cell_type":"markdown","source":"# TESTE PARA XGB\n","metadata":{}},{"cell_type":"code","source":"cv = StratifiedKFold(n_splits = 5, shuffle = True)\ny_pred = cross_val_predict(SVM, x_teste, y_teste, cv = cv)\nfig, ax = plt.subplots()\nsns.heatmap(confusion_matrix(y_teste, y_pred), annot=True, \n            ax=ax, fmt='d', cmap='Reds')\nax.set_title(\"Matriz de Confusão\", fontsize=18)\nax.set_ylabel(\"True label\")\nax.set_xlabel(\"Predicted Label\")\n# relatório do modelo\nprint('Relatório de classificação:\\n', classification_report(y_teste, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:50.554386Z","iopub.execute_input":"2021-10-24T02:33:50.554872Z","iopub.status.idle":"2021-10-24T02:33:52.122702Z","shell.execute_reply.started":"2021-10-24T02:33:50.554827Z","shell.execute_reply":"2021-10-24T02:33:52.121771Z"},"trusted":true},"execution_count":672,"outputs":[]},{"cell_type":"markdown","source":"# TREINAMENTO RANDOM FOREST","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(x_treino,y_treino)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:52.124090Z","iopub.execute_input":"2021-10-24T02:33:52.124352Z","iopub.status.idle":"2021-10-24T02:33:53.596346Z","shell.execute_reply.started":"2021-10-24T02:33:52.124320Z","shell.execute_reply":"2021-10-24T02:33:53.595486Z"},"trusted":true},"execution_count":673,"outputs":[]},{"cell_type":"markdown","source":"# TESTE RANDOM FOREST","metadata":{}},{"cell_type":"code","source":"cv = StratifiedKFold(n_splits = 5, shuffle = True)\ny_pred = cross_val_predict(rf, x_teste, y_teste, cv = cv)\nfig, ax = plt.subplots()\nsns.heatmap(confusion_matrix(y_teste, y_pred), annot=True, \n            ax=ax, fmt='d', cmap='Reds')\nax.set_title(\"Matriz de Confusão\", fontsize=18)\nax.set_ylabel(\"True label\")\nax.set_xlabel(\"Predicted Label\")\n# relatório do modelo\nprint('Relatório de classificação:\\n', classification_report(y_teste, y_pred, digits=4))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T02:33:53.597782Z","iopub.execute_input":"2021-10-24T02:33:53.599015Z","iopub.status.idle":"2021-10-24T02:33:56.045467Z","shell.execute_reply.started":"2021-10-24T02:33:53.598966Z","shell.execute_reply":"2021-10-24T02:33:56.044725Z"},"trusted":true},"execution_count":674,"outputs":[]},{"cell_type":"markdown","source":"# CONSIDERAÇÕES FINAIS\n\n## INFELIZMENTE NÃO TIVE TEMPO SUFICIENTE PARA TESTAR OUTROS MODELOS NEM APLICAR ENGENHARIA DE FEATURES QUE TROUXESSEM BENEFICIOS\n\n### XGB SE MOSTROU MAIS EFICAZ OBTENDO 95.46% DE ACCURACY E 95.36% DE F1-SCORE","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}